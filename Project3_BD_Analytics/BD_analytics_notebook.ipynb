{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - BD Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext # for RDDs\n",
    "from pyspark.sql import SparkSession # for DFs\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "                    .appName('BDM_project3')\n",
    "                    .getOrCreate()\n",
    "        ) # for DFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- n_citation: long (nullable = true)\n",
      " |-- references: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- venue: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading in all the files\n",
    "#files = [\"dblp-ref-0.json\", \"dblp-ref-1.json\", \"dblp-ref-2.json\", \"dblp-ref-3.json\"]\n",
    "files = [\"dblp-ref-3.json\"] # testing with one file\n",
    " \n",
    "papers_df = (spark.read\n",
    "             .option(\"inferSchema\", True) # Letting Spark itself define the schema\n",
    "             .json(files) \n",
    "            )\n",
    "\n",
    "papers_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+\n",
      "|            abstract|             authors|                  id|n_citation|          references|               title|               venue|year|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+\n",
      "|AdaBoost algorith...|[Zheng Xu, Runbin...|001eef4f-1d00-4ae...|         0|[0a11984c-ab6e-4b...|A Heterogeneous S...|high performance ...|2016|\n",
      "|In this paper, a ...|[Yufei Liang, Yan...|002e0b7e-d62f-414...|         0|                  []|A novel conformal...|international con...|2016|\n",
      "|This paper studie...|[Xiaodong Ai, Key...|00352759-f0a7-467...|         0|[1862a08a-08c6-4a...|A source-seeking ...|international con...|2016|\n",
      "|                NULL|[Francine Berman,...|00f77fa9-ae49-493...|         0|                  []|Social and ethica...|Communications of...|2017|\n",
      "|                NULL|[Leon A. Sakkal, ...|013ea675-bb58-42f...|        50|[4f4f200c-0764-4f...|Prediction of con...|Journal of Comput...|2017|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subset of the dataframe\n",
    "papers_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79007, 8)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the dataframe\n",
    "print((papers_df.count(), len(papers_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " abstract   | AdaBoost algorithm based on Haar-like features can achieves high accuracy (above 95%) in object detection. Meanwhile massive computing power is needed to implement the cascaded classifiers involved in AdaBoost detection. To solve this problem, several dedicated hardware solutions have been proposed for real-time applications. In this work, a novel heterogeneous architecture of an AdaBoost detector is presented. This architecture achieves higher performance while consuming fewer hardware resources. By combining an integrated ARM Cortex-A9 processor with a dedicated accelerator, this architecture can be configured to realize various objects detection by simply loading different parameters. 2-D parallelism is involved in accelerator unit combination which brings more flexibility. This scheme is implemented on Xilinx ZC702 platform, the experiment result shows that 40 QVGA frames per second can be achieved for real-time face detection. The accelerator achieves more than 13 times improvement over the OpenCV implementation on a standalone Cortex-A9 w.r.t execution speed. Meanwhile, the accelerator consumes 40% less FPGA hardware resources than the prior-art implementation. \n",
      " authors    | [Zheng Xu, Runbin Shi, Zhihao Sun, Yaqi Li, Yuanjia Zhao, Chenjian Wu]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      " id         | 001eef4f-1d00-4ae6-8b4f-7e66344bbc6e                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      " n_citation | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      " references | [0a11984c-ab6e-4b75-9291-e1b700c98d52, 1f4152a3-481f-4adf-a29a-2193a3d4303c, 3c2ddf0a-237b-4d17-8083-c90df5f3514b, 522ce553-29ea-4e0b-9ad3-0ed4eb9de065, 579e5f24-5b13-4e92-b255-0c46d066e306, 5d0b987d-eed9-42ce-9bf3-734d98824f1b, 80656b4d-b24c-4d92-8753-bdb965bcd50a, d6e37fb1-5f7e-448e-847b-7d1f1271c574]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " title      | A Heterogeneous System for Real-Time Detection with AdaBoost                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " venue      | high performance computing and communications                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " year       | 2016                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First row\n",
    "papers_df.show(n=1, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-----+----------+----------+-----+-----+-----+\n",
      "|abstract|authors|   id|n_citation|references|title|venue| year|\n",
      "+--------+-------+-----+----------+----------+-----+-----+-----+\n",
      "|   44970|  79007|79007|     79007|     49546|79007|79007|79007|\n",
      "+--------+-------+-----+----------+----------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of non-NaN values in each column\n",
    "# https://stackoverflow.com/questions/33900726/count-number-of-non-nan-entries-in-each-column-of-spark-dataframe-in-pyspark\n",
    "\n",
    "from pyspark.sql.functions import col, count, isnan, lit, sum\n",
    "\n",
    "def count_not_null(c, nan_as_null=False):\n",
    "    pred = col(c).isNotNull() & (~isnan(c) if nan_as_null else lit(True))\n",
    "    return sum(pred.cast(\"integer\")).alias(c)\n",
    "\n",
    "papers_df.agg(*[count_not_null(c) for c in papers_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>79007</td>\n",
       "      <td>79007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>7.607566418165479</td>\n",
       "      <td>2014.6681053577531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>51.072850795288396</td>\n",
       "      <td>5.48549815947471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>7091</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary          n_citation                year\n",
       "0   count               79007               79007\n",
       "1    mean   7.607566418165479  2014.6681053577531\n",
       "2  stddev  51.072850795288396    5.48549815947471\n",
       "3     min                   0                1955\n",
       "4     max                7091                2018"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics (for numeric columns)\n",
    "papers_df.describe(\"n_citation\", \"year\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keeping the English documents\n",
    "\n",
    "# !pip install langdetect\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from langdetect import detect, LangDetectException\n",
    "# Only keeping the English documents\n",
    "def detect_language(text):\n",
    "    if text:\n",
    "        try:\n",
    "            return detect(text)\n",
    "        except:\n",
    "            return 'unknown'\n",
    "    return 'unknown'\n",
    "detect_language_udf = udf(detect_language, StringType())\n",
    "papers_df = papers_df.withColumn(\"language\", detect_language_udf(papers_df.abstract))\n",
    "papers_df = papers_df.filter(papers_df.language == 'en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords (with Gensim)\n",
    "# !pip install gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords #!pip install gensim\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    if text is not None:\n",
    "        return remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove custom stopwords\n",
    "custom_stop_words = [ 'doi',\n",
    "'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure','rights',\n",
    "'reserved', 'permission', 'used', 'using', 'biorxiv', 'medrxiv', 'license', 'fig', 'fig.', 'al.', 'Elsevier',\n",
    "'PMC', 'CZI', 'www']\n",
    "def remove_custom_stop_words(text):\n",
    "    if text is not None:\n",
    "        words = text.split()\n",
    "        filtered_words = [word for word in words if word not in custom_stop_words]\n",
    "        return ' '.join(filtered_words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "import re\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    if text is not None:\n",
    "        return re.sub(r'[!()\\[\\]{};:\\'\"\\,<>./?@#$%^&*_~]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.functions import regexp_extract, col\n",
    "\n",
    "# Create a user-defined function (UDF)\n",
    "remove_stop_words_udf = F.udf(remove_stop_words, StringType()) # Default return type is string\n",
    "custom_stop_words_udf = F.udf(remove_custom_stop_words, StringType()) # Default return type is string\n",
    "remove_punctuation_udf = F.udf(remove_punctuation, StringType()) # Default return type is string\n",
    "\n",
    "# Apply the UDF \n",
    "# Remove stop words\n",
    "papers_df = papers_df.withColumn(\"abstract\", remove_stop_words_udf(papers_df[\"abstract\"]))\n",
    "papers_df = papers_df.withColumn(\"title\", remove_stop_words_udf(papers_df[\"title\"]))\n",
    "\n",
    "# Convert into a lowercase\n",
    "papers_df = papers_df.withColumn('abstract', lower(papers_df['abstract']))\n",
    "papers_df = papers_df.withColumn('title', lower(papers_df['title']))\n",
    "\n",
    "# Remove custom stop words\n",
    "papers_df = papers_df.withColumn(\"abstract\", custom_stop_words_udf(papers_df[\"abstract\"]))\n",
    "papers_df = papers_df.withColumn(\"title\", custom_stop_words_udf(papers_df[\"title\"]))\n",
    "\n",
    "# Remove punctuation\n",
    "papers_df = papers_df.withColumn('abstract', remove_punctuation_udf(papers_df['abstract']))\n",
    "papers_df = papers_df.withColumn('title', remove_punctuation_udf(papers_df['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " abstract   | adaboost algorithm based haar-like features achieves high accuracy above 95 object detection meanwhile massive computing power needed implement cascaded classifiers involved adaboost detection to solve problem dedicated hardware solutions proposed real-time applications in work novel heterogeneous architecture adaboost detector presented this architecture achieves higher performance consuming fewer hardware resources by combining integrated arm cortex-a9 processor dedicated accelerator architecture configured realize objects detection simply loading different parameters 2-d parallelism involved accelerator unit combination brings flexibility this scheme implemented xilinx zc702 platform experiment result shows 40 qvga frames second achieved real-time face detection the accelerator achieves 13 times improvement opencv implementation standalone cortex-a9 wrt execution speed meanwhile accelerator consumes 40 fpga hardware resources prior-art implementation \n",
      " authors    | [Zheng Xu, Runbin Shi, Zhihao Sun, Yaqi Li, Yuanjia Zhao, Chenjian Wu]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " id         | 001eef4f-1d00-4ae6-8b4f-7e66344bbc6e                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " n_citation | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " references | [0a11984c-ab6e-4b75-9291-e1b700c98d52, 1f4152a3-481f-4adf-a29a-2193a3d4303c, 3c2ddf0a-237b-4d17-8083-c90df5f3514b, 522ce553-29ea-4e0b-9ad3-0ed4eb9de065, 579e5f24-5b13-4e92-b255-0c46d066e306, 5d0b987d-eed9-42ce-9bf3-734d98824f1b, 80656b4d-b24c-4d92-8753-bdb965bcd50a, d6e37fb1-5f7e-448e-847b-7d1f1271c574]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " title      | a heterogeneous system real-time detection adaboost                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " venue      | high performance computing and communications                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " year       | 2016                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " language   | en                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "papers_df.show(n=1, truncate=False, vertical=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, col\n",
    "\n",
    "# Combine title and abstract into one column\n",
    "papers_df = papers_df.fillna({'title': '', 'abstract': ''})\n",
    "papers_df = papers_df.withColumn(\"text\", concat_ws(\" \", col(\"title\"), col(\"abstract\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+--------+--------------------+\n",
      "|            abstract|             authors|                  id|n_citation|          references|               title|               venue|year|language|                text|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+--------+--------------------+\n",
      "|adaboost algorith...|[Zheng Xu, Runbin...|001eef4f-1d00-4ae...|         0|[0a11984c-ab6e-4b...|a heterogeneous s...|high performance ...|2016|      en|a heterogeneous s...|\n",
      "|in paper kind nov...|[Yufei Liang, Yan...|002e0b7e-d62f-414...|         0|                  []|a novel conformal...|international con...|2016|      en|a novel conformal...|\n",
      "|this paper studie...|[Xiaodong Ai, Key...|00352759-f0a7-467...|         0|[1862a08a-08c6-4a...|a source-seeking ...|international con...|2016|      en|a source-seeking ...|\n",
      "|this paper presen...|[Vincent Buntinx,...|01522369-3b88-425...|         0|[426b57a8-2e7d-49...|studying linguist...|Frontiers in Digi...|2017|      en|studying linguist...|\n",
      "|boneh durfee euro...|[Atsushi Takayasu...|01537b60-9ae2-468...|         0|                NULL|small secret expo...|international sym...|2016|      en|small secret expo...|\n",
      "|container identif...|[Ankit Verma, Mon...|017440d5-6ba8-422...|         0|[3e3a4245-eb62-47...|automatic contain...|international con...|2016|      en|automatic contain...|\n",
      "|this paper analyz...|[Elaine Vedrasco,...|01dcc2e7-fda1-483...|         0|[472b9486-b98a-49...|effective solutio...|                    |2016|      en|effective solutio...|\n",
      "|for stereoscopic ...|[Long Qian, Alexa...|01f02fae-97df-420...|        50|[076bca9b-b30c-4c...|modeling physical...|international sym...|2016|      en|modeling physical...|\n",
      "|without requiring...|[Aijie Zou, Yuxua...|029bb71a-6b91-43a...|         0|[0b92c76b-86f0-4b...|delay analysis co...|international con...|2016|      en|delay analysis co...|\n",
      "|this work establi...|[P. Karpiński, Jo...|0361b05e-9bca-42d...|         0|[65cbef5a-007f-43...|a high-performanc...|                    |2017|      en|a high-performanc...|\n",
      "|transforming dete...|[Jan Křetínský, T...|037d2e92-a3b1-406...|         0|[0c781683-b162-45...|index appearance ...|tools and algorit...|2017|      en|index appearance ...|\n",
      "|the relevance loc...|[Nicola Maiellaro...|0391f5e3-13f4-498...|         0|[49365bcd-f1aa-4f...|one-page multimed...|                    |2017|      en|one-page multimed...|\n",
      "|in work consider ...|[Maria Dimou, The...|03d34ab5-a275-444...|         0|[35fc2508-4727-4a...|topology experime...|panhellenic confe...|2016|      en|topology experime...|\n",
      "|ever-evolving mal...|[Ekta Gandotra, D...|03f1c773-c072-401...|         0|                NULL|tools  techniques...|                    |2016|      en|tools  techniques...|\n",
      "|a network embeddi...|[Zhipeng Huang, N...|04cd6546-ed71-4fe...|         0|[0613c93b-e309-42...|heterogeneous inf...|arXiv: Artificial...|2017|      en|heterogeneous inf...|\n",
      "|metaheuristics ge...|[Giovani Guizzo, ...|04d72bcc-7998-4a8...|         0|[16bc6bb0-748a-42...|metaheuristic des...|                    |2016|      en|metaheuristic des...|\n",
      "|betweenness centr...|[Leonardo Maccari...|055c731d-eead-439...|         0|[03a2eb6c-8a96-46...|on computation ce...|global communicat...|2016|      en|on computation ce...|\n",
      "|in paper motivate...| [Paul Raff, Ze Jin]|05944f08-b0df-47b...|         0|[1f35f20b-a760-47...|the difference-of...|                    |2016|      en|the difference-of...|\n",
      "|time-triggered et...|[Xuan Zhou, Feng ...|05de0628-5f0d-4c5...|         0|[03a8b814-c726-44...|network calculus ...|                    |2016|      en|network calculus ...|\n",
      "|for multiterminal...|[Chung Chan, Manu...|0600c67e-71a1-4ed...|        50|[19eb4d23-c01f-48...|secret key agreem...|arXiv: Informatio...|2017|      en|secret key agreem...|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "papers_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
    "from pyspark.sql.functions import size\n",
    "\n",
    "# Tokenize the combined text\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "tokenized_data = tokenizer.transform(papers_df)\n",
    "\n",
    "# Filter out rows where 'words' column is null or empty\n",
    "filtered_data = tokenized_data.filter(size(col(\"words\")) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize using Word2Vec\n",
    "word2vec = Word2Vec(vectorSize=3, minCount=1, inputCol=\"words\", outputCol=\"features1\", numPartitions=4)\n",
    "word2vec_model = word2vec.fit(filtered_data)\n",
    "result = word2vec_model.transform(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow method for number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "pca = PCA(k=3, inputCol=\"features1\", outputCol=\"features\")\n",
    "pca_model = pca.fit(result)\n",
    "pca_result = pca_model.transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_result = pca_result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca_result.select(\"features\").show(n=5, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repartition data if necessary\n",
    "pca_result = pca_result.repartition(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = []\n",
    "\n",
    "for k in range(2, 21):\n",
    "    kmeans = KMeans(k=k, seed=3)\n",
    "    model = kmeans.fit(pca_result)\n",
    "    evaluator = ClusteringEvaluator()  \n",
    "    cost.append(model.summary.trainingCost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(int(range(2, 21)), cost, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means (from practise session)\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=6, seed=42)\n",
    "model = kmeans.fit(pca_result) # What shape should transformed_data be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the clusters using the model\n",
    "clusters = model.transform(pca_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance =  0.47008049439904004\n"
     ]
    }
   ],
   "source": [
    "# Evaluating: the silhouette value\n",
    "\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(clusters)\n",
    "print('Silhouette with squared euclidean distance = ', silhouette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+--------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|            abstract|             authors|                  id|n_citation|          references|               title|               venue|year|language|                text|               words|           features1|            features|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+--------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|a number improvem...|[Rostislav V. Lap...|2c4fa78a-7e5f-400...|         0|[9ab4d920-d1c9-42...|an improved param...|arXiv: Optimizati...|2017|      en|an improved param...|[an, improved, pa...|[0.24362396326790...|[-0.1854054560534...|         5|\n",
      "|prostate cancer c...|[Xiaolong Jia, Yi...|c5bd58c9-e4fa-473...|         0|[611b24f9-6437-4c...|application seque...|Computational Bio...|2017|      en|application seque...|[application, seq...|[0.22033959801041...|[0.06286124353060...|         4|\n",
      "|lexidb scalable c...|[Matt Coole, Paul...|ad269e31-1bd2-40f...|         0|[14aa4d03-a681-4f...|lexidb a scalable...|                    |2016|      en|lexidb a scalable...|[lexidb, a, scala...|[0.22194420555681...|[0.26980738828651...|         4|\n",
      "|big data acknowle...|[Adiska Fardani H...|80d64bc1-910b-473...|         2|[01e91804-c4cc-44...|antecedents big d...|                    |2016|      en|antecedents big d...|[antecedents, big...|[0.19768487154082...|[0.40038399686533...|         0|\n",
      "|to cater demands ...|[Xiaohu Ge, Song ...|3d51d55b-76d8-405...|         0|[15c572ec-d7b7-47...|two-scale cost ef...|arXiv: Networking...|2016|      en|two-scale cost ef...|[two-scale, cost,...|[0.01362280852551...|[0.26408242978353...|         2|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+--------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clusters.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import FloatType\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return random.random()\n",
    "    #return float(v1.dot(v2) / (v1.norm(2) * v2.norm(2)))\n",
    "    #return np.dot(v1,v2)/(norm(v1)*norm(v2))\n",
    "\n",
    "# Create a user-defined function (UDF)\n",
    "cosine_similarity_udf = F.udf(cosine_similarity, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_papers(title, cluster_nr, vector, top_papers):\n",
    "\n",
    "    # Only wanted cluster\n",
    "    cluster = clusters.filter((clusters.prediction==cluster_nr)) \n",
    "    # Finding the score for every row (article)\n",
    "    cluster = cluster.withColumn(\"score\", cosine_similarity_udf(cluster[\"features\"], lit(vector)))\n",
    "    # Sorting based on score\n",
    "    #cluster = cluster.sort(cluster.score.desc()).collect()\n",
    "    cluster = cluster.sort(F.col(\"score\").desc())\n",
    "    # Returning top papers ( +1 because we return this paper itself)\n",
    "    top6 = cluster.limit(top_papers)\n",
    "    \n",
    "    return top6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"extending soft sets optimality decision based multiple decisions same data\"\n",
    "cluster_nr = 0\n",
    "return_paper_amount = 5\n",
    "vector = [-0.10243023044169974,0.11760577260862987,-0.1057083581270069,-0.1793964755532844,-0.0763572113374742,0.06533546890329417,0.05405455779683669,0.0014953876143246753,0.05579619871718542,-0.06045485277158717,-0.031985408328361255,-0.0065214477254662735,0.055045270135136444,-0.039381974801982335,0.1150758126529062,0.04839263885073337,0.00924491386608666,-0.047626787554568506,0.062001876267498854,0.23482869677353602] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+--------+--------------------+--------------------+--------------------+--------------------+----------+----------+\n",
      "|            abstract|             authors|                  id|n_citation|          references|               title|               venue|year|language|                text|               words|           features1|            features|prediction|     score|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+--------+--------------------+--------------------+--------------------+--------------------+----------+----------+\n",
      "|the paper based c...|[Heng Wang, Xin W...|31bd5651-63b3-41a...|         0|[cf97d226-bed1-4c...|functional resear...|biomedical engine...|2016|      en|functional resear...|[functional, rese...|[0.22399424616190...|[0.20781050853468...|         0|0.99986273|\n",
      "|social media incr...|[Tanushree Mitra,...|07715c33-025b-437...|        50|[012d9aaf-34d0-49...|a parsimonious la...|conference on com...|2017|      en|a parsimonious la...|[a, parsimonious,...|[0.24492799907397...|[0.29755329385317...|         0| 0.9998562|\n",
      "|as koreas standar...|[Dong-Hoon Lee, J...|669a3464-f2df-4c6...|         0|                  []|remote applicatio...|advances in mobil...|2016|      en|remote applicatio...|[remote, applicat...|[0.13508270233693...|[0.39668583022467...|         0| 0.9997137|\n",
      "|identity theft de...|[Razieh Nokhbeh Z...|ef765f72-d9ca-432...|        50|[0f71e66b-81d4-4f...|risk kit highligh...|intelligence and ...|2016|      en|risk kit highligh...|[risk, kit, highl...|[0.20536706520244...|[0.36957257325295...|         0|0.99965715|\n",
      "|due opportunities...|[Masafumi Yamada,...|133976ce-9f80-458...|         0|[0b3df83d-afb4-4a...|performance evalu...|advanced informat...|2017|      en|performance evalu...|[performance, eva...|[0.21147627533545...|[0.28241576830821...|         0| 0.9993558|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+--------+--------------------+--------------------+--------------------+--------------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_papers = recommend_papers(title, cluster_nr, vector, return_paper_amount)\n",
    "top_papers.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
