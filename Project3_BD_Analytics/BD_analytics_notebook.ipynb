{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - BD Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext # for RDDs\n",
    "from pyspark.sql import SparkSession # for DFs\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "                    .appName('BDM_project3')\n",
    "                    .getOrCreate()\n",
    "        ) # for DFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- n_citation: long (nullable = true)\n",
      " |-- references: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- venue: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "papers_df = (spark.read\n",
    "             .option(\"inferSchema\", True) # Letting Spark itself define the schema\n",
    "             .json(\"dblp-ref-3.json\")\n",
    "            )\n",
    "\n",
    "papers_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+\n",
      "|            abstract|             authors|                  id|n_citation|          references|               title|               venue|year|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+\n",
      "|AdaBoost algorith...|[Zheng Xu, Runbin...|001eef4f-1d00-4ae...|         0|[0a11984c-ab6e-4b...|A Heterogeneous S...|high performance ...|2016|\n",
      "|In this paper, a ...|[Yufei Liang, Yan...|002e0b7e-d62f-414...|         0|                  []|A novel conformal...|international con...|2016|\n",
      "|This paper studie...|[Xiaodong Ai, Key...|00352759-f0a7-467...|         0|[1862a08a-08c6-4a...|A source-seeking ...|international con...|2016|\n",
      "|                NULL|[Francine Berman,...|00f77fa9-ae49-493...|         0|                  []|Social and ethica...|Communications of...|2017|\n",
      "|                NULL|[Leon A. Sakkal, ...|013ea675-bb58-42f...|        50|[4f4f200c-0764-4f...|Prediction of con...|Journal of Comput...|2017|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subset of the dataframe\n",
    "papers_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " abstract   | AdaBoost algorithm based on Haar-like features can achieves high accuracy (above 95%) in object detection. Meanwhile massive computing power is needed to implement the cascaded classifiers involved in AdaBoost detection. To solve this problem, several dedicated hardware solutions have been proposed for real-time applications. In this work, a novel heterogeneous architecture of an AdaBoost detector is presented. This architecture achieves higher performance while consuming fewer hardware resources. By combining an integrated ARM Cortex-A9 processor with a dedicated accelerator, this architecture can be configured to realize various objects detection by simply loading different parameters. 2-D parallelism is involved in accelerator unit combination which brings more flexibility. This scheme is implemented on Xilinx ZC702 platform, the experiment result shows that 40 QVGA frames per second can be achieved for real-time face detection. The accelerator achieves more than 13 times improvement over the OpenCV implementation on a standalone Cortex-A9 w.r.t execution speed. Meanwhile, the accelerator consumes 40% less FPGA hardware resources than the prior-art implementation. \n",
      " authors    | [Zheng Xu, Runbin Shi, Zhihao Sun, Yaqi Li, Yuanjia Zhao, Chenjian Wu]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      " id         | 001eef4f-1d00-4ae6-8b4f-7e66344bbc6e                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      " n_citation | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      " references | [0a11984c-ab6e-4b75-9291-e1b700c98d52, 1f4152a3-481f-4adf-a29a-2193a3d4303c, 3c2ddf0a-237b-4d17-8083-c90df5f3514b, 522ce553-29ea-4e0b-9ad3-0ed4eb9de065, 579e5f24-5b13-4e92-b255-0c46d066e306, 5d0b987d-eed9-42ce-9bf3-734d98824f1b, 80656b4d-b24c-4d92-8753-bdb965bcd50a, d6e37fb1-5f7e-448e-847b-7d1f1271c574]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " title      | A Heterogeneous System for Real-Time Detection with AdaBoost                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " venue      | high performance computing and communications                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " year       | 2016                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First row\n",
    "papers_df.show(n=1, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>79007</td>\n",
       "      <td>79007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>7.607566418165479</td>\n",
       "      <td>2014.6681053577531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>51.072850795288375</td>\n",
       "      <td>5.485498159474597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>7091</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary          n_citation                year\n",
       "0   count               79007               79007\n",
       "1    mean   7.607566418165479  2014.6681053577531\n",
       "2  stddev  51.072850795288375   5.485498159474597\n",
       "3     min                   0                1955\n",
       "4     max                7091                2018"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics (for numeric columns)\n",
    "papers_df.describe(\"n_citation\", \"year\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features\n",
    "\n",
    "# Add more??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in /opt/conda/lib/python3.11/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from langdetect) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keeping the English documents\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from langdetect import detect, LangDetectException\n",
    "# Only keeping the English documents\n",
    "def detect_language(text):\n",
    "    if text:\n",
    "        try:\n",
    "            return detect(text)\n",
    "        except:\n",
    "            return 'unknown'\n",
    "    return 'unknown'\n",
    "detect_language_udf = udf(detect_language, StringType())\n",
    "papers_df = papers_df.withColumn(\"language\", detect_language_udf(papers_df.abstract))\n",
    "papers_df = papers_df.filter(papers_df.language == 'en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.11/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.11/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.11/site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords (with Gensim)\n",
    "from gensim.parsing.preprocessing import remove_stopwords #!pip install gensim\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    if text is not None:\n",
    "        return remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove custom stopwords\n",
    "custom_stop_words = [ 'doi',\n",
    "'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure','rights',\n",
    "'reserved', 'permission', 'used', 'using', 'biorxiv', 'medrxiv', 'license', 'fig', 'fig.', 'al.', 'Elsevier',\n",
    "'PMC', 'CZI', 'www']\n",
    "def remove_custom_stop_words(text):\n",
    "    if text is not None:\n",
    "        words = text.split()\n",
    "        filtered_words = [word for word in words if word not in custom_stop_words]\n",
    "        return ' '.join(filtered_words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "import re\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    if text is not None:\n",
    "        return re.sub(r'[!()\\[\\]{};:\\'\"\\,<>./?@#$%^&*_~]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.functions import regexp_extract, col\n",
    "\n",
    "# Create a user-defined function (UDF)\n",
    "remove_stop_words_udf = F.udf(remove_stop_words, StringType()) # Default return type is string\n",
    "custom_stop_words_udf = F.udf(remove_custom_stop_words, StringType()) # Default return type is string\n",
    "remove_punctuation_udf = F.udf(remove_punctuation, StringType()) # Default return type is string\n",
    "\n",
    "# Apply the UDF \n",
    "# Remove stop words\n",
    "papers_df = papers_df.withColumn(\"abstract\", remove_stop_words_udf(papers_df[\"abstract\"]))\n",
    "papers_df = papers_df.withColumn(\"title\", remove_stop_words_udf(papers_df[\"title\"]))\n",
    "\n",
    "# Convert into a lowercase\n",
    "papers_df = papers_df.withColumn('abstract', lower(papers_df['abstract']))\n",
    "papers_df = papers_df.withColumn('title', lower(papers_df['title']))\n",
    "\n",
    "# Remove custom stop words\n",
    "papers_df = papers_df.withColumn(\"abstract\", custom_stop_words_udf(papers_df[\"abstract\"]))\n",
    "papers_df = papers_df.withColumn(\"title\", custom_stop_words_udf(papers_df[\"title\"]))\n",
    "\n",
    "# Remove punctuation\n",
    "papers_df = papers_df.withColumn('abstract', remove_punctuation_udf(papers_df['abstract']))\n",
    "papers_df = papers_df.withColumn('title', remove_punctuation_udf(papers_df['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " abstract   | adaboost algorithm based haar-like features achieves high accuracy above 95 object detection meanwhile massive computing power needed implement cascaded classifiers involved adaboost detection to solve problem dedicated hardware solutions proposed real-time applications in work novel heterogeneous architecture adaboost detector presented this architecture achieves higher performance consuming fewer hardware resources by combining integrated arm cortex-a9 processor dedicated accelerator architecture configured realize objects detection simply loading different parameters 2-d parallelism involved accelerator unit combination brings flexibility this scheme implemented xilinx zc702 platform experiment result shows 40 qvga frames second achieved real-time face detection the accelerator achieves 13 times improvement opencv implementation standalone cortex-a9 wrt execution speed meanwhile accelerator consumes 40 fpga hardware resources prior-art implementation \n",
      " authors    | [Zheng Xu, Runbin Shi, Zhihao Sun, Yaqi Li, Yuanjia Zhao, Chenjian Wu]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " id         | 001eef4f-1d00-4ae6-8b4f-7e66344bbc6e                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " n_citation | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " references | [0a11984c-ab6e-4b75-9291-e1b700c98d52, 1f4152a3-481f-4adf-a29a-2193a3d4303c, 3c2ddf0a-237b-4d17-8083-c90df5f3514b, 522ce553-29ea-4e0b-9ad3-0ed4eb9de065, 579e5f24-5b13-4e92-b255-0c46d066e306, 5d0b987d-eed9-42ce-9bf3-734d98824f1b, 80656b4d-b24c-4d92-8753-bdb965bcd50a, d6e37fb1-5f7e-448e-847b-7d1f1271c574]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " title      | a heterogeneous system real-time detection adaboost                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " venue      | high performance computing and communications                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " year       | 2016                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " language   | en                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "papers_df.show(n=1, truncate=False, vertical=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
    "\n",
    "# Converting data for ML algorithms\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer(inputCol=\"abstract\", outputCol=\"abstract_words\")\n",
    "papers_df = tokenizer.transform(papers_df)\n",
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"title_words\")\n",
    "papers_df = tokenizer.transform(papers_df)\n",
    "\n",
    "# Train Word2Vec model on abstract\n",
    "word2Vec_abstract = Word2Vec(vectorSize=3, minCount=0, inputCol=\"abstract_words\", outputCol=\"abstract_word_vectors\")\n",
    "model_abstract = word2Vec_abstract.fit(papers_df)\n",
    "papers_df = model_abstract.transform(papers_df)\n",
    "\n",
    "# Train Word2Vec model on title\n",
    "word2Vec_title = Word2Vec(vectorSize=3, minCount=0, inputCol=\"title_words\", outputCol=\"title_word_vectors\")\n",
    "model_title = word2Vec_title.fit(papers_df)\n",
    "papers_df = model_title.transform(papers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------+\n",
      "|title_words                                                                                                                     |title_word_vectors                                               |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------+\n",
      "|[a, heterogeneous, system, real-time, detection, adaboost]                                                                      |[0.13081834806750217,0.2661234525342782,0.11660287280877431]     |\n",
      "|[a, novel, conformal, jigsaw, ebg, structure, design]                                                                           |[0.21808177831449677,0.07638901409726323,-0.18523061594792772]   |\n",
      "|[a, source-seeking, strategy, autonomous, underwater, vehicle, on-line, field, estimation]                                      |[0.24470417905184957,0.18191318276027837,0.16030625585052702]    |\n",
      "|[studying, linguistic, changes, 200, years, newspapers, resilient, words, analysis]                                             |[0.08512019779947068,0.06295664877527289,-0.07132511875695652]   |\n",
      "|[small, secret, exponent, attacks, rsa, unbalanced, prime, factors]                                                             |[-0.0076097974088042974,0.015947213403705973,0.11934817838482559]|\n",
      "|[automatic, container, code, recognition, spatial, transformer, networks, connected, component, region, proposals]              |[-0.04409123652360656,0.3695986435155977,-0.015966373961418867]  |\n",
      "|[effective, solution, medical, tourism, aggregative, data, mining, approach]                                                    |[0.1728755033109337,0.2102120349300094,-0.1168422392802313]      |\n",
      "|[modeling, physical, structure, additional, constraints, stereoscopic, optical, see-through, head-mounted, display, calibration]|[0.12445875253020362,0.10145397450436246,0.0728313611312346]     |\n",
      "|[delay, analysis, completely, irrepressible, sequences, mobile, ad, hoc, networks]                                              |[-0.08160255932145648,0.42031470106707675,0.6958435417877303]    |\n",
      "|[a, high-performance, portable, abstract, interface, explicit, simd, vectorization]                                             |[0.10107403948131832,-0.01859835028881207,-0.1022239763988182]   |\n",
      "|[index, appearance, record, transforming, rabin, automata, parity, automata]                                                    |[0.1478075310587883,0.18699648627080023,0.024121048860251904]    |\n",
      "|[one-page, multimedia, interactive, map]                                                                                        |[0.18448618799448013,0.23029894195497036,0.045325664803385735]   |\n",
      "|[topology, experimentation, zigbee, wireless, sensor, network]                                                                  |[-0.2158874310553074,0.5540946448842684,0.7292623557150364]      |\n",
      "|[tools, , techniques, malware, analysis, classification]                                                                        |[0.11903999870022137,0.27897384328146774,-0.23997649115820724]   |\n",
      "|[heterogeneous, information, network, embedding, meta, path, based, proximity]                                                  |[0.025707861175760627,0.39485724456608295,0.21406150027178228]   |\n",
      "|[metaheuristic, design, pattern, visitor, genetic, operators]                                                                   |[0.18866421282291412,0.195109902570645,-0.0014274679124355316]   |\n",
      "|[on, computation, centrality, metrics, network, security, mesh, networks]                                                       |[-0.05835748557001352,0.3028380200266838,0.3378632131498307]     |\n",
      "|[the, difference-of-datasets, framework, a, statistical, method, discover, insight]                                             |[0.24650340247899294,0.08710413705557585,-0.18150072917342186]   |\n",
      "|[network, calculus, worst-case, latency, analysis, ttethernet, preemption, transmission, mode]                                  |[0.04364576232102182,0.22251341885162723,0.18649009801447392]    |\n",
      "|[secret, key, agreement, discussion, rate, constraints]                                                                         |[0.10090893879532814,0.10409452657525738,0.18425506477554637]    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the results\n",
    "papers_df.select(\"title_words\", \"title_word_vectors\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means and elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
