{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 4 - Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install flwr[simulation] \n",
    "#flwr_datasets[vision] torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall --no-deps cryptography==41.0.7\n",
    "#When it gives error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "#from flwr_datasets import FederatedDataset\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")\n",
    "disable_progress_bar()\n",
    "import torch\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 3 # Trying with smaller amount of clients??? Maybe helps idk\n",
    "BATCH_SIZE = 32\n",
    "CLIENT_FOLDER = \"/kaggle/input/bdm-dataset/client\"\n",
    "\n",
    "def load_datasets():\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "\n",
    "    for client_id in range(NUM_CLIENTS):\n",
    "        client_folder = os.path.join(CLIENT_FOLDER, str(client_id))\n",
    "\n",
    "        train_x = torch.from_numpy(np.load(os.path.join(client_folder, 'trainx.pyp'), allow_pickle=True))\n",
    "        train_y = torch.from_numpy(np.load(os.path.join(client_folder, 'trainy.pyp'), allow_pickle=True))\n",
    "        test_x = torch.from_numpy(np.load(os.path.join(client_folder, 'testx.pyp'), allow_pickle=True))\n",
    "        test_y = torch.from_numpy(np.load(os.path.join(client_folder, 'testy.pyp'), allow_pickle=True))\n",
    "\n",
    "        train_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "        test_dataset = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "        valloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "        trainloaders.append(trainloader)\n",
    "        valloaders.append(valloader)\n",
    "\n",
    "    return trainloaders, valloaders\n",
    "\n",
    "trainloaders, valloaders = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainloaders[0].dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = next(iter(trainloaders[0]))\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in trainloaders:\n",
    "    print(len(batch.dataset[0:][0]), \"images\")\n",
    "    #print(batch.dataset[0:][1], \"label?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs: int, verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            images = images.permute(0, 3, 1, 2)\n",
    "            labels = labels.argmax(dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            #print(images.shape, labels.shape)\n",
    "            outputs = net(images)\n",
    "            #outputs = outputs.argmax(dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            images = images.permute(0, 3, 1, 2)\n",
    "            labels = labels.argmax(dim=1)\n",
    "            #print(images.shape, labels.shape)\n",
    "            outputs = net(images)\n",
    "            #outputs = outputs.argmax(dim=1)\n",
    "            #print(outputs.shape)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            #all_predictions.extend(torch.nn.functional.one_hot(predicted, num_classes=outputs.size(1)).cpu().numpy())\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)#53\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    #roc = roc_auc_score(all_labels, all_predictions, multi_class='ovr')\n",
    "    #return loss, accuracy, kappa, f1, roc\n",
    "    print(f\"Loss: {loss}, accuracy {accuracy}, kappa {kappa}, f1 {f1}\")\n",
    "    return loss, accuracy, kappa, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Federated learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flower Client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=3)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        #loss, accuracy, kappa, f1, roc = test(self.net, self.valloader)\n",
    "        loss, accuracy, kappa, f1 = test(self.net, self.valloader)\n",
    "        #return float(loss), len(self.valloader), {\"accuracy\": float(accuracy), \"kappa\": float(kappa), \"f1\": float(f1), \"roc\": float(roc)}\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy), \"kappa\": float(kappa), \"f1\": float(f1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    model = models.vgg16()\n",
    "    input_lastLayer = model.classifier[6].in_features\n",
    "    model.classifier[6] = nn.Linear(input_lastLayer,10)\n",
    "    net = model.to(DEVICE)\n",
    "    #net = models.vgg16().to(DEVICE)\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(net, trainloader, valloader).to_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "'''def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Initialize sums for all metrics\n",
    "    loss_sum = accuracy_sum = kappa_sum = f1_sum = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    # Compute sums for all metrics\n",
    "    for num_examples, m in metrics:\n",
    "        loss_sum += num_examples * m[\"loss\"]\n",
    "        accuracy_sum += num_examples * m[\"accuracy\"]\n",
    "        kappa_sum += num_examples * m[\"kappa\"]\n",
    "        f1_sum += num_examples * m[\"f1\"]\n",
    "        total_examples += num_examples\n",
    "\n",
    "    # Compute weighted averages for all metrics\n",
    "    loss_avg = loss_sum / total_examples\n",
    "    accuracy_avg = accuracy_sum / total_examples\n",
    "    kappa_avg = kappa_sum / total_examples\n",
    "    f1_avg = f1_sum / total_examples\n",
    "\n",
    "    return {\"loss\": loss_avg, \"accuracy\": accuracy_avg, \"kappa\": kappa_avg, \"f1\": f1_avg}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "    min_fit_clients=2,  # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=2,  # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=2,  # Wait until all 10 clients are available\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "\n",
    "# Specify the resources each of your clients need. By default, each\n",
    "# client will be allocated 1x CPU and 0x GPUs\n",
    "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0.0}\n",
    "if DEVICE.type == \"cuda\":\n",
    "    # here we are assigning an entire GPU for each client.\n",
    "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0}\n",
    "    # Refer to our documentation for more details about Flower Simulations\n",
    "    # and how to setup these `client_resources`.\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=50),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
