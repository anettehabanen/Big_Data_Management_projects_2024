{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the project code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"DF2_Practice\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "#spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True) # OK for exploration, not great for performance\n",
    "#spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import shapely\n",
    "from shapely import Point\n",
    "from shapely.geometry import mapping, shape\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "from shapely import Polygon\n",
    "from pyspark.sql.functions import col, count, when\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from shapely.strtree import STRtree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in taxi dataset\n",
    "taxiDataDf = (spark.read\n",
    "             .option(\"sep\", \",\") # separator\n",
    "             .option(\"header\", True) # file has header row\n",
    "             .option(\"inferSchema\", True) # spark tries to infer data types\n",
    "             .csv(\"trip_data/trip_data_1.csv\") #path\n",
    "            ) \\\n",
    "            .dropna(subset=[\"pickup_datetime\",\"dropoff_datetime\",\"pickup_longitude\",\"pickup_latitude\",\"dropoff_longitude\",\"dropoff_latitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[medallion: string, hack_license: string, vendor_id: string, rate_code: int, store_and_fwd_flag: string, pickup_datetime: timestamp, dropoff_datetime: timestamp, passenger_count: int, trip_time_in_secs: int, trip_distance: double, pickup_longitude: double, pickup_latitude: double, dropoff_longitude: double, dropoff_latitude: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(taxiDataDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in borough dataset\n",
    "with open('nyc-boroughs.geojson') as file:\n",
    "    boroughs = json.load(file)\n",
    "\n",
    "features = boroughs['features']\n",
    "properties = [feature['properties'] for feature in features]\n",
    "geometry = [feature['geometry'] for feature in features]\n",
    "\n",
    "rowNumberWindow = Window.orderBy(F.lit(\"a\"))\n",
    "\n",
    "properties_df = spark.createDataFrame(properties).withColumn(\"rid\",F.row_number().over(rowNumberWindow))\n",
    "geometry_df = spark.createDataFrame(geometry).withColumn(\"rid\",F.row_number().over(rowNumberWindow))\n",
    "borough_base_df = properties_df.join(geometry_df,(\"rid\")).drop(\"rid\") #rid - row_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[@id: string, borough: string, boroughCode: bigint, coordinates: array<array<array<double>>>, type: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(borough_base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[@id: string, borough: string, boroughCode: bigint, coordinates: array<array<array<double>>>, type: string, area: double, row_id: int]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the area size of the boroughs\n",
    "def calculate_area(coordinates):\n",
    "    polygon = Polygon(list(coordinates[0]))\n",
    "    return polygon.area\n",
    "\n",
    "calculate_area_udf = F.udf(calculate_area,DoubleType())\n",
    "\n",
    "borough_df_sorted = borough_base_df.withColumn(\"area\",calculate_area_udf(F.col(\"coordinates\"))) \\\n",
    "                            .sort(F.col(\"area\").desc()) \\\n",
    "                            .withColumn(\"row_id\",F.row_number().over(rowNumberWindow) - 1)\n",
    "\n",
    "\n",
    "# https://shapely.readthedocs.io/en/stable/strtree.html\n",
    "geomtree = STRtree([Polygon(coords[\"coordinates\"][0]) for coords in borough_df_sorted.select(\"coordinates\").collect()])\n",
    "borough_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBorough(x,y):\n",
    "    point = Point(x,y)\n",
    "    nearestLocIndex = geomtree.nearest(point)\n",
    "    return nearestLocIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to find the point borough\n",
    "def update_borough(longitude, latitude):\n",
    "    borough = findBorough(longitude, latitude)\n",
    "    return int(borough) if borough is not None else -1\n",
    "\n",
    "# Create a user-defined function (UDF)\n",
    "update_borough_udf = F.udf(update_borough, IntegerType())\n",
    "\n",
    "# Apply the UDF to update the start and end borough column (finding the borough index)\n",
    "taxiDataDf_with_boroughs = taxiDataDf.withColumn(\"startBoroughIndex\", update_borough_udf(taxiDataDf[\"pickup_longitude\"], taxiDataDf[\"pickup_latitude\"]))\n",
    "taxiDataDf_with_boroughs = taxiDataDf_with_boroughs.withColumn(\"endBoroughIndex\", update_borough_udf(taxiDataDf[\"dropoff_longitude\"], taxiDataDf[\"dropoff_latitude\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[startBoroughIndex: int, count: bigint]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxiDataDf_with_boroughs.groupBy(\"startBoroughIndex\").count().orderBy(\"startBoroughIndex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1: Utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilization: This is per taxi/driver. This can be computed by computing the idle \n",
    "time per taxi. We will elaborate on that more later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[medallion: string, hack_license: string, vendor_id: string, rate_code: int, store_and_fwd_flag: string, pickup_datetime: timestamp, dropoff_datetime: timestamp, passenger_count: int, trip_time_in_secs: int, trip_distance: double, pickup_longitude: double, pickup_latitude: double, dropoff_longitude: double, dropoff_latitude: double, startBoroughIndex: int, endBoroughIndex: int, idle_time: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "taxiUtilizationBaseDf = taxiDataDf_with_boroughs.filter(\"trip_time_in_secs > 0 or trip_time_in_secs <= 3600 * 4\")\n",
    "              \n",
    "\n",
    "utilizationWindow = Window.partitionBy(\"hack_license\").orderBy(\"pickup_datetime\")\n",
    "\n",
    "idleTimeDf = taxiUtilizationBaseDf.withColumn(\"idle_time\",(F.col(\"pickup_datetime\") - F.lag(F.col(\"dropoff_datetime\")).over(utilizationWindow)).cast(\"long\")) \\\n",
    "                                  .fillna(0,subset=[\"idle_time\"])\n",
    "display(idleTimeDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hack_license: string, idle_time_sum_seconds: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query1_df = idleTimeDf.groupBy(\"hack_license\").agg(F.sum(\"idle_time\").alias(\"idle_time_sum_seconds\"))\n",
    "display(query1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save result to file\n",
    "query1_df.coalesce(1).write.mode(\"overwrite\").csv(\"results/m1/query1.csv\",header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2: Average next trip time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average time it takes for a taxi to find its next fare(trip) per destination borough. This can be computed by finding the time difference, e.g. in seconds, between the trip's drop off and the next trip's pick up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|      borough|avg_waiting_time|\n",
      "+-------------+----------------+\n",
      "|       Queens|           31.58|\n",
      "|     Brooklyn|           22.61|\n",
      "|Staten Island|           40.39|\n",
      "|    Manhattan|           10.39|\n",
      "|        Bronx|           33.57|\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, unix_timestamp, lead, avg, round\n",
    "\n",
    "windowSpec = Window.partitionBy(\"hack_license\").orderBy(\"dropoff_datetime\")\n",
    "\n",
    "df = taxiDataDf_with_boroughs.withColumn(\"next_pickup_time\", lead(\"pickup_datetime\").over(windowSpec))\n",
    "df = df.withColumn(\"time_to_next_fare\", unix_timestamp(\"next_pickup_time\") - unix_timestamp(\"dropoff_datetime\"))\n",
    "df = df.filter((col(\"time_to_next_fare\") >= 0) & (col(\"time_to_next_fare\") <= 3600*4))  \n",
    "\n",
    "result_df = df.join(borough_df_sorted, df.endBoroughIndex == borough_df_sorted.row_id)\n",
    "avg_wait_time_per_borough = result_df.groupBy(\"borough\").agg(round(avg(\"time_to_next_fare\") / 60 , 2).alias(\"avg_waiting_time\"))\n",
    "\n",
    "avg_wait_time_per_borough.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3: Trips started in one borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of trips that started and ended within the same borough,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of trips that start and end in the same borough is 13118340.\n"
     ]
    }
   ],
   "source": [
    "same_borough_df = taxiDataDf_with_boroughs.filter(F.col(\"startBoroughIndex\") == F.col(\"endBoroughIndex\"))\n",
    "print(\"The number of trips that start and end in the same borough is \" + str(same_borough_df.count()) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 4: Trips between different boroughs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of trips that started in one borough and ended in another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of trips that have different start and end borough is 1658189.\n"
     ]
    }
   ],
   "source": [
    "different_borough_df = taxiDataDf_with_boroughs.filter(F.col(\"startBoroughIndex\") != F.col(\"endBoroughIndex\"))\n",
    "print(\"The number of trips that have different start and end borough is \" + str(different_borough_df.count()) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
